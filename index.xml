<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS Study Group</title>
    <link>https://cse-study.github.io/</link>
    <description>Recent content on CS Study Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>©2019 Notepadium.</copyright>
    <lastBuildDate>Thu, 10 Mar 2022 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://cse-study.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Matrix Encoding Networks for Neural Combinatorial Optimization</title>
      <link>https://cse-study.github.io/ai/2022-03/220310-matnet/</link>
      <pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/220310-matnet/</guid>
      <description>&lt;p&gt;Samsung SDS Techtonic의 MatNet(NeurIPS 2021) 발표를 보고 이를 정리합니다.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cse-study.github.io/ai/2022-03/220306-pomo/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;이전 포스팅&lt;/a&gt;
도 참고 하시면 좋습니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;조합 최적화: 운송 경로 최적화, 설비 운영 최적화, 자원 할당 최적화 등, 굉장히 많은 경우의 수에 대해서 가장 좋은 결과를 내는 경우를 찾는 문제&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;도시간 이동 소요시간 최적화 문제, 혹은 외판원 문제(TSP)같은 조합최적화 문제를 데이터로 만들면 행렬의 형태가 됨. 그리고 이 행렬의 크기는 데이터에 따라 계속해서 변경될 수 있음(도시가 더 추가되는 경우). 또 다른 문제로는 &amp;lsquo;승객이 기다리는 시간의 합이 최소가 되도록 택시를 배차&amp;rsquo;하는 문제도 있음. 이 문제에서 아래와 같이 별표(*)친 내용을 찾으면 최적이라고 가정해보겠음&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;승객 1&lt;/th&gt;
&lt;th&gt;승객 2&lt;/th&gt;
&lt;th&gt;승객 3&lt;/th&gt;
&lt;th&gt;승객 4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;택시 1&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;45 (*)&lt;/td&gt;
&lt;td&gt;70&lt;/td&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;택시 2&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;60&lt;/td&gt;
&lt;td&gt;10 (*)&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;택시 3&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;65&lt;/td&gt;
&lt;td&gt;95&lt;/td&gt;
&lt;td&gt;5 (*)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;택시 4&lt;/td&gt;
&lt;td&gt;30 (*)&lt;/td&gt;
&lt;td&gt;85&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;행의 정보(택시1)를 보고 최적(40)을 확인해보고, 해당 최적 데이터(40)의 열에 대해서 다시 최적(20)을 확인해보고, 또 해당 최적 데이터(20)의 행에 대해서 최적(5)을 확인해보고&amp;hellip; 를 반복하면, 전체적인 최적을 파악할 수 있다는 아이디어에서 시작함&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 아이디어를 기반으로, 각 행과 열 데이터를 임베딩 벡터로 만든 뒤에 해당 임베딩 벡터들을 서로 반복해서 곱해주는 방식으로 네트워크를 구성함. query/key가 등장하는 것으로 보아 아마 attention 기반의 구조를 사용하지 않았을까 싶음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;최종적으로는 각 row, 각 column 마다의 대표 임베딩 벡터가 출력됨(택시의 임베딩이 각각 출력, 승객의 임베딩이 각각 출력). 그리고 목적 row의 임베딩을 column의 임베딩들과 비교함으로써 최적이 무엇일지를 판단하는 방식임(택시1 임베딩과 승객1, 2, 3, 4의 임베딩을 비교한 결과를 기반으로, 택시 1과 승객 사이의 최적 선택)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그러면 학습을 어떻게 이루어지는가?: 영상에서는 시간이 없어 따로 소개하고 있지 않음 🥲&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;동영상만 보고는 제대로 이해할 수 없었음.. 매우매우 대략적인 내용만 파악할 수 있었음. 따라서 조합최적화의 기초 공부를 하고 관련 논문들을 읽어볼 계획&lt;/li&gt;
&lt;li&gt;예전에 연구할 때 매트릭스를 인코딩한다는 개념에 대해 생각해본 적이 있어서 많이 찾아봤는데, 그 당시에는 관련 논문을 하나도 찾지 못해서 아이디어를 버려뒀음. 따라서 이런 방식이 있다는 것이 반가웠고 추후 매트릭스 인코딩이 필요한 경우가 생긴다면 해당 방식을 참고해보면 좋겠다는 생각이 들었음.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=hAirBRQSFm0&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;[Techtonic 2021] AI를 사용해 기업의 조합최적화 작업을 처리할 수 있을까? (NeurIPS 2021) - 권영대 프로&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Kwon, Yeong-Dae, et al. &amp;ldquo;Matrix encoding networks for neural combinatorial optimization.&amp;rdquo; &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 34 (2021).&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>POMO: Policy Optimization with Multiple Optima for Reinforcement Learning</title>
      <link>https://cse-study.github.io/ai/2022-03/220306-pomo/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/220306-pomo/</guid>
      <description>&lt;p&gt;Samsung SDS Techtonic의 &amp;ldquo;POMO: 강화학습을 이용한 조합 최적화(NeurIPS 2020)&amp;rdquo; 발표를 보고 이를 정리합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;조합 최적화(Combinatorial Optimization): 주어진 아이템들의 최적 순서 또는 매핑을 찾는 문제 (ex. 생산 설비 운영 최적화, 자원 할당 최적화, 운송 경로 최적화 등)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;대표적인 예시는 &amp;lsquo;외판원 문제&amp;rsquo;(Traveling Salesman Problem, TSP): 모든 도시를 여행하기 위한 경로 최적화하는 문제&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Naive approach로는 Trial &amp;amp; Error 후에 가장 최적인 경로를 확인하는 것. 하지만 이 방법은 너무 오래 걸림. 최적의 해를 찾기보다는, 최적에 가까운 해를 빠른 시간에 찾아내는 방법(Heuristic)이 현실적&lt;/li&gt;
&lt;li&gt;개선된 휴리스틱 방법(체계적인 trial &amp;amp; error)은, 만들어져 있는 조합에서 조금씩 변형을 가해 다시 시도해보는 것. 하지만 좋은 변형/조합 방법은 문제마다 다르기 때문에 전문가의 수작업 중요&lt;/li&gt;
&lt;li&gt;AI로 푸는 방법은, 실전 문제를 풀기 전 비슷한 케이스를 반복해 학습한 후에 실전에서는 one-shot 솔루션 제공. 속도 매우 빠르고 데이터에서 스스로 전략 학습 가능&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;강화학습에서 baseline 결정의 난제&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Baseline에 대한 설명은 &lt;a href=&#34;https://dnddnjs.gitbooks.io/rl/content/actor-critic_policy_gradient.html&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;링크&lt;/a&gt;
 참고하면 좋을듯&lt;/li&gt;
&lt;li&gt;인공지능이 반복해 풀어 얻는 솔루션은 보통 비슷하고 크게 다르지 않음. 따라서 학습 공간 안에서의 local optimum에 수렴한다는 문제 발생&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Local optima 문제 해결 아이디어&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;같은 문제를 다른 문제인 것 처럼 여러가지 방법으로 포장하여, 인공지능이 각각을 다른 방법으로 풀도록 유도. 이것이 POMO의 전략임&lt;/li&gt;
&lt;li&gt;즉, POMO는 multiple optima를 사용한 강화학습 방법임&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple optima&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5-node TSP(외판원 문제)를 예로 들면, geometry 상 optima는 하나인데, 이를 sequence로 표현하거나 search tree 형태로 표현하면 optima가 5개로 늘어남. 표현을 어떻게 하느냐에 따라서 optima 수가 달라질 수 있음&lt;/li&gt;
&lt;li&gt;기존 방식들은 이 5개 중 하나를 잘 찾도록 하는 알고리즘들이었다면, POMO는 어떻게 하면 이 5개를 다 잘 찾아낼 수 있을까를 고민하였음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;POMO baseline 결정법&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;서로 다른 시작점으로부터 문제를 풀도록 한 후 결과를 종합하여 baseline 결정&lt;/li&gt;
&lt;li&gt;Instance augmentation: 문제를 대칭/회전 변환하여 (인공지능이 보기에) 새로운 문제를 만듦. 좌표만 바꿨을 뿐이지만 인공지능이 풀 때는 완전히 다른 계산이 필요함&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;모든 조합 최적화 문제가 multiple optima를 가지는 것은 아닌데, 거의 대부분이 문제에서 multiple optima를 찾을 수 있음. 그래서 multiple optima를 이용하면 강화학습 할 때 큰 효과를 얻을 수 있다는 것이 논문의 핵심&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;조합 최적화 관련 실제 문제들&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;생산 설비 최적화(Job shop, Flow shop problem): 20종의 핸드폰 제작 스케쥴, 3단계 제작, 어떤 순서로 제작해야 할까?&lt;/li&gt;
&lt;li&gt;자원 할당 최적화(Resource management problem): 20개의 프로그램을 컴퓨터(클라우드)에서 처리. 프로그램들은 공유된 자원(CPU, GPU, memory)를 할당받아 사용, 어떤 순서로 할당해야 할까?&lt;/li&gt;
&lt;li&gt;운송 경로 최적화(capacitated vehicle routing problem): 100개의 지점. 각 지점 당 지정된 할당량 배송. 트럭의 적재 한계량 존재. 어떤 경로/순서로 배송해야 할까?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;조합최적화 문제를 강화학습으로 풀려는 시도들이 최근 많이 있음&lt;/li&gt;
&lt;li&gt;강화학습을 처음 공부할 때는 강화학습이 풀 수 있는 실제 세상의 문제가 많이 있을지 의문이었는데, 실제 세상에서 적용할 수 있지만 아직 사람들이 가치를 발견하지 못한 경우가 많겠다는 생각이 들었음&lt;/li&gt;
&lt;li&gt;조합 최적화를 들어보긴 했지만 실제로 어떤 내용인지는 영상을 통해 처음으로 접했음. 내용이 흥미로워서 기초부터 주요 논문까지 쭉 순서대로 제대로 공부해보고 싶다는 생각이 들었음&lt;/li&gt;
&lt;li&gt;2021 발표도 있는 듯 하여 다음 주에는 해당 발표를 보거나, 조합최적화를 기초부터 살펴보는 포스팅을 올릴 계획&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Dyp9lQpVgCs&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;[Techtonic 2020] Track 1. POMO: 강화학습을 이용한 조합 최적화(NeurIPS 2020) - 권영대 프로&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=hAirBRQSFm0&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;[Techtonic 2021] AI를 사용해 기업의 조합최적화 작업을 처리할 수 있을까? (NeurIPS 2021) - 권영대 프로&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper/2020/hash/f231f2107df69eab0a3862d50018a9b2-Abstract.html&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;POMO: Policy Optimization with Multiple Optima for Reinforcement Learning&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ChemAI</title>
      <link>https://cse-study.github.io/ai/2022-03/20220305-chemai/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/20220305-chemai/</guid>
      <description>&lt;p&gt;2021년 8월 한국화학연구원에서 발표한 ChemAI와 관련된 자료들을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;화학, 소재 분야에서도 최근 머신 러닝을 이용한 연구들이 많이 진행되고 있습니다. 분자가 어떤 특성을 가질지, 원하는 성질을 갖는 분자 구조를 어떻게 디자인 할 것인지, 어떻게 합성 과정을 최적화할지 등 여러 방면으로 머신 러닝을 활용할 수 있습니다. 벌써 네이처 퍼블리싱 그룹의 10% 정도가 머신 러닝과 관련된 연구라고 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 화학 분야에서 이를 적용하기에는 어려움 또한 따릅니다. 연구 환경을 세팅하는 것이 복잡하게 느껴질 수 있으며 SMILES 등 구조적인 관계를 나타내는 데이터를 수치적으로 바꿔야 해서 데이터 전처리가 쉽지만은 않습니다. 또한 화학 분야 전문가들이 생소한 머신러닝 알고리즘에 대해 공부하고 하이퍼 파라미터 최적화와 evaluation까지 진행하려면 많은 시간과 노력이 필요할 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;한국화학연구원은 이를 해결하기 위해 ChemAI를 만들었습니다. ChemAI는 웹 베이스이기 때문에 누구나 쉽게 접근이 가능합니다. 자동으로 데이터를 수치 데이터로 변환하고 적합한 알고리즘을 선택해 줍니다(연구 목적이나 물질에 따라 알고리즘을 선택하는 것은 매우 중요합니다. 머신 러닝이 아닌 기존 DFT(density functional theory) 시뮬레이션에서도 물질이 crystal인지, 금속인지, 반도체인지, 단백질인지 등에 따라 다른 프로그램과 방법을 사용합니다). 이후 자동으로 hyperparameter 최적화와 evaluation, visualization까지 진행해 줍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;알고리즘은 crystal GNN(소재 분야 SOTA), symbolic regression, 화학연구원에서 자체 개발한 DopNet 등 총 16가지가 제공됩니다. SMILES 구조의 성질을 예측하는 데는 GNN을 사용했고 crystal structure의 경우 mendeleev, pytorch geometric 등을 이용했다고 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;머신 러닝은 여러 분야에서 문제를 더 쉽고 빠르게 해결할 수 있는 방법이 될 수 있습니다. 하지만 이를 활용하는 것이 쉽지는 않기 때문에 문제 해결의 선택지에서 고려되지 않는 경우도 많습니다.&lt;/li&gt;
&lt;li&gt;따라서 ChemAI와 같이 누구든지 쉽게 이용 가능하도록 만든 머신 러닝 툴의 역할과 의미가 매우 크다고 생각합니다. 이는 화학 분야에 종사하는 사람들의 시간과 노력을 아껴주고 새로운 발견을 해 낼 가능성을 높여줄 것입니다.&lt;/li&gt;
&lt;li&gt;화학공학과 컴퓨터 공학을 전공하다가 처음 머신 러닝에 관심을 가지게 된 이유도 이러한 맥락이었습니다. 지금은 여러 이유로 조금은 다른 길을 가고 있기는 하지만 언젠가 이런 프로그램을 만들어 보고 싶네요.&lt;/li&gt;
&lt;li&gt;DopNet에 대해서도 다루려고 했는데 글이 길어져서 다음 주에 다룰 예정입니다. 관심이 있으시면 “Predicting thermoelectric properties from chemical formula with explicitly identifying dopant effects” 를 읽어 보시길 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Q7vL1rSG-pk&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.youtube.com/watch?v=Q7vL1rSG-pk&lt;/a&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Magnetic control of tokamak plasmas</title>
      <link>https://cse-study.github.io/ai/2022-02/20220227-magnetic-control-of-tokamak-plasmas/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/20220227-magnetic-control-of-tokamak-plasmas/</guid>
      <description>&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;딥마인드와 스위스 로잔연방공대 플라즈마 센터가 심층 강화학습을 이용해 토카막에서의 플라즈마 제어를 성공적으로 수행했다. 이는 네이처 2022.2월 호에 게재되었다.&lt;/li&gt;
&lt;li&gt;플라즈마 제어를 위한 코일 전류의 조절은 선형화된 모델을 기반으로 한다. 하지만 이는 복잡한 실시간 계산이 필요하며 목표 플라즈마 구성이 변경될 때마다 상당한 공학적, 설계적 노력을 기울여야 한다. 따라서 비선형 컨트롤러를 생성하고 제어를 용이하게 하기 위해 심층 강화학습을 도입하였다.&lt;/li&gt;
&lt;li&gt;실험 목표는 시간 변화에 따른 원하는 제어 값 등으로 설정했다. Extended Table 4에서 찾아볼 수 있다. 학습은 토카막 시뮬레이터와의 상호 작용을 통해 이루어지며 제어 정책은 하드웨어에서 실시간으로 직접 실행된다(제로 샷).&lt;/li&gt;
&lt;li&gt;하지만 지속적으로 변하는 플라즈마 상태를 계산해야 하기 때문에 시뮬레이터에서 공급되는 데이터 속도는 일반적인 강화학습 환경에 비해 매우 느리다. 이 문제는 maximum a posteriori policy optimization(MPO)를 적용하여 극복했다고 한다.&lt;/li&gt;
&lt;li&gt;플라즈마 제어를 위한 모델에서 중요한 점은 정해진 시간 안에 빠르게 실행이 가능해야 한다는 것이다. 해당 실험에서 쓰인 TCV의 경우 50us라는 시간이 사용 가능했다. 이를 맞추기 위해 불필요한 것들을 제외하고, tfcompile 등을 이용한 바이너리 컴파일 등 여러 방면으로 최적화를 하였다.&lt;/li&gt;
&lt;li&gt;결과적으로 19개 자기 코일로 이루어진 토카막을 한 번에 제어할 수 있는 간결한 제어 환경을 구축하였고 원하는 플라즈마 모양을 시간에 따라 잘 제어할 수 있었다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;단순히 시뮬레이팅이나 이론으로 끝나는 것이 아닌 실제 환경에 적용하여 좋은 결과를 냈다는 점이 유의미하다고 생각한다.&lt;/li&gt;
&lt;li&gt;완전히 새로운 알고리즘을 제안했다기 보다는 실제 적용을 위해 많은 엔지니어링적 노력을 한 것 같다. 제한된 시간 안에 작동하도록 한 것과 제로 샷으로 좋은 성과를 얻은 것이 특히 더 대단해 보인다.&lt;/li&gt;
&lt;li&gt;MPO에 대해 공부해 봐야겠다..&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s41586-021-04301-9&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.nature.com/articles/s41586-021-04301-9&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>OpenAI Embeddings API</title>
      <link>https://cse-study.github.io/ai/2022-02/220227-openai-embeddings/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/220227-openai-embeddings/</guid>
      <description>&lt;p&gt;2022년 1월에 OpenAI에서 발표한 &amp;ldquo;Text and Code Embeddings by Contrastive Pre-Training&amp;rdquo; 논문의 관련 자료들을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OpenAI에서 GPT-3의 text (or code) embedding 결과를 쉽게 얻을 수 있도록 돕는 Embeddings API라는 툴을 공개함&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;입력 text(or code)와 엔진 이름을 입력하면, 해당 입력의 vector representation(embedding)을 얻을 수 있음&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;openai&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Embedding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;canine companions say&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;text-similarity-davinci-001&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;관련하여 3가지 대표적인 use-cases(: Text Similarity, Text Search, Code Search)를 제공함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;편의를 위해 &lt;code&gt;delicious beans&lt;/code&gt;과 같이 N개의 단어 조합으로 이루어진 Embeddings API 입력 text를 &amp;lsquo;쿼리&amp;rsquo;라고 칭하겠음. Text similarity는 두 개의 쿼리에 대해 API를 사용하여 유사도를 구하는 작업이고, Text Search는 주어진 쿼리에 대해 가장 유사도가 높은 도큐먼트를 데이터 셋 내에서 찾아내는 (쿼리와 도큐먼트 사이의 유사도를 구하는) 작업이고, Code Search는 주어진 쿼리에 대해 가장 유사도가 높은 함수(혹은 코드)를 데이터 셋 내에서 찾아내는 작업이라고 생각하면 됨.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;링크&lt;/a&gt;
에 따르면, Embeddings API는 논문에서 말하는 것 처럼 성능이 현재 다른 모델들 대비 그렇게 좋은 것은 아니고, 모델과 feature dimension이 매우 커서 cost가 너무 높고, 토큰당 가격도 너무나 비싸다고 말하고 있음. (Davinci 모델의 경우 12288 dimensions을 사용하고 토큰당 0.6달러이기 때문에, 일반 유저가 사용하는 것은 거의 불가능하지 싶음)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI Blogs, &lt;a href=&#34;https://openai.com/blog/introducing-text-and-code-embeddings/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&amp;ldquo;Introducing Text and Code Embeddings in the OpenAI API&amp;rdquo;.&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Yannic Kilcher YouTube, &lt;a href=&#34;https://www.youtube.com/watch?v=5skIqoO3ku0&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&amp;ldquo;OpenAI Embeddings (and Controversy?!)&amp;rdquo;.&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenAI Embeddings API: &lt;a href=&#34;https://beta.openai.com/docs/guides/embeddings&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://beta.openai.com/docs/guides/embeddings&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Nils Reimers, &lt;a href=&#34;https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&amp;ldquo;OpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?&amp;quot;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Data2Vec</title>
      <link>https://cse-study.github.io/ai/2022-02/220218-data2vec/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/220218-data2vec/</guid>
      <description>&lt;p&gt;2022년 1월에 Meta AI에서 발표한 &lt;strong&gt;Data2vec&lt;/strong&gt; 블로그 포스팅을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;현재의 self-supervised learning 연구들은 image, speech, text 등 각기 다른 modality마다 학습 방법에 차이가 크다.&lt;/li&gt;
&lt;li&gt;따라서 Meta AI는 multiple modality(e.b. image, speech, text)에서 작동하는 data2vec을 개발하였으며, data2vec은 기존 computer vision, speech 분야의 알고리즘 성능을 넘었고, NLP 분야에서는 견줄만큼의 성능을 기록하였다.&lt;/li&gt;
&lt;li&gt;Data2vec은 기존에 self-supervised learning에서 자주 사용되던 contrastive learning이나, reconstructing the input example 방식을 사용하지는 않는다.&lt;/li&gt;
&lt;li&gt;Data2vec은 input data에 대한 own representation을 맞추도록 학습시킨다.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Teacher network에 데이터를 넣어 출력된 representation을 target으로 설정한다.&lt;/li&gt;
&lt;li&gt;Student network에는 데이터에 일부 masking을 가해서 넣어 representation을 얻어내고, 이 representation이 teacher의 target representation과 동일해지도록 모델을 학습시킨다.&lt;/li&gt;
&lt;li&gt;Teacher와 student는 동일한 네트워크이지만 weight 값이 살짝 다르다. (&lt;a href=&#34;https://yuhodots.github.io/deeplearning/21-04-04/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;BYOL&lt;/a&gt;
 처럼 exponentialmoving average 사용)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised learning 중에서도 BYOL의 아이디어를 차용하여 multi-modal learning 알고리즘을 고안한 것이 재미있었음&lt;/li&gt;
&lt;li&gt;하나의 backbone으로 image, speech, text 관련 task에 모두 적용 가능하다는 것이, 현재까지의 multi-modal 연구 중에 가장 자연스러운 방법이라는 생각이 들며 future work들이 기대됨&lt;/li&gt;
&lt;li&gt;Label이 필요없고, multi-modality에서 작동하고, single-purpose algorithms보다 잘하는 AI 모델. 이것이 앞으로의 AI의 주요 방향성이 되지 않을까 싶음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Data2vec블로그 포스팅: &lt;a href=&#34;https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;The first high-performance self-supervised algorithm that works for speech, vision, and text&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Data2vec paper: &lt;a href=&#34;https://ai.facebook.com/research/data2vec-a-general-framework-for-self-supervised-learning-in-speech-vision-and-language&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Data2vec code: &lt;a href=&#34;https://github.com/pytorch/fairseq/tree/main/examples/data2vec&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/pytorch/fairseq/tree/main/examples/data2vec&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>GT Sophy</title>
      <link>https://cse-study.github.io/ai/2022-02/20220214-gt-sophy/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/20220214-gt-sophy/</guid>
      <description>&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;img src=&#34;https://media.springernature.com/w200/springer-static/cover-hires/journal/41586/602/7896&#34; alt=&#34;Volume 602 Issue 7896&#34; style=&#34;zoom:100%; display: block; margin-left: auto; margin-right: auto;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;2022년 2월 소니 AI가 개발한 자동차 경주 AI가 네이처 표지를 장식했음. 게임 이름은 그란 투스리모 스포츠임.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인공지능 이름은 GT Sophy. Model free, off-policy deepRL을 이용했음. Distributional SAC과 비슷하지만 value backup 과 target functions가 다른 QR-SAC을 이용했다고 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;게임의 리얼리즘 때문에 생각보다 어려웠다고 함. 또한 규정화되어 있지 않은 스포츠맨십을 지키며 너무 공격적이지도 소극적이지도 않게 플레이 하기 위한 보상 체계를 만드는 것이 힘들었다고 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습 방법: PS4에서 실행되는 GT인스턴스를 제어하는 rollout worker에게 트레이닝 시나리오를 배포하면 각 agent는 가장 최근 policy의 사본을 실행시키고 action을 전송함. 비동기적으로 다음 프레임을 계산해 새로운 상태를 알아냄. State, action, reward 튜플을 ERB에 저장함. 트레이너는 policy를 업데이트하기 위해 ERB를 샘플링함.&lt;/p&gt;
&lt;img src=&#34;https://cse-study.github.io/assets/img/image-20220214181447986.png&#34; alt=&#34;image-20220214181447986&#34; style=&#34;zoom:30%; display: block; margin-left: auto; margin-right: auto;&#34; /&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;강화학습을 이용해 게임에 적용시키는 경우가 점점 늘어나는 것 같음. 적용시키기 좋고, 흥미로우며 이슈도 되기 때문이라 생각함. 개인적으로도 해 보고 싶다는 생각이 들었음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AI vs 사람 구도의 실험에서는 AI와 사람 간 공평성을 위한 적절한 방법들이 고려되어야 함. 예를 들어 알파스타의 경우 평균 APM에 제한을 두었지만 중요한 교전 상황에 압도적인 순간 APM을 보이며 승리했음. 사람의 경우 APM이 모두 의미 있는 동작을 뜻하지 않으므로 실제 차이는 더 컸었다 해석할 수 있음. 해당 실험에서도 여러 사항을 고려하여 제약을 두었음. 논문의 Fairness versus humans에서 찾아볼 수 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;개발진들이 이런 연구를 하는 이유는 사람과 싸워 이기는 AI를 만들기 위함이 아니라 사람을 더 잘 이해하고, 더 재미있으며 흥미로운 탐험과 새로운 경험을 사용자에게 제공하기 위함이라 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;연구의 의미를 항상 생각하는 것이 중요함을 다시 한 번 느꼈음. 새로운 방법과 좋은 성능 자체도 의미있지만 이들이 앞으로의 연구와 우리의 삶에 어떤 긍정적인 역할을 할지 깊게 생각한다면 더 좋을 것 같다는 생각을 했음.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s41586-021-04357-7&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.nature.com/articles/s41586-021-04357-7&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/l948hMaTPuo&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://youtu.be/l948hMaTPuo&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AlphaCode</title>
      <link>https://cse-study.github.io/ai/2022-02/220205-alphacode/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/220205-alphacode/</guid>
      <description>&lt;p&gt;2022년 2월에 딥마인드에서 발표한 &lt;strong&gt;AlphaCode&lt;/strong&gt; 블로그 포스팅을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AlphaCode란?: competitive programming task를 human-level로 풀 수 있는 시스템. Codeforces의 10개 대회에 대해 테스트 했을 때, 참가자들의 평균 수준의 성능 달성 (상위 54%)&lt;/li&gt;
&lt;li&gt;Model: Transformer-based langauge model 이라고 포스팅에 언급되어 있음. Language generation(code generation)이 주요 역할인 것으로 보아 decoder-centric langauge model 중 하나를 사용했을 것으로 생각됨. 그 뒤에 promising program으로 결과를 필터링했다고 하는데, rule-based로 결과를 필터링 했다는 의미로 대충 이해했음 (promising program의 정확한 의미를 아는 분 있으면 코멘트 부탁드립니다)&lt;/li&gt;
&lt;li&gt;Training: Github code로 pre-training하고, competitive programming task에 대해 fine-tuning 진행하였음 (일반적인 language model 학습하는 방식과 동일하게)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Attention 기반 시각화가 너무 아름다움🥺 기회가 되면 나중에 한번 만들어보고 싶음&lt;/li&gt;
&lt;li&gt;포스팅 원문에서 방법론 추가에 따른 모델의 발전과정을 볼 수 있음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Alphacode 블로그 포스팅: &lt;a href=&#34;https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Competitive programming with AlphaCode&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Alphacode 시각화: &lt;a href=&#34;https://alphacode.deepmind.com/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;AlphaCode Attention Visualization&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Alphacode paper: &lt;a href=&#34;https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Alphacode dataset: &lt;a href=&#34;https://github.com/deepmind/code_contests&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/deepmind/code_contests&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://cse-study.github.io/help/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/help/</guid>
      <description>&lt;h3 id=&#34;shortcuts&#34;&gt;Shortcuts&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;스터디에 도움이되는 자료들을 모아두는 공간입니다. 좋은 자료가 있다면 아래에 계속 추가해주세요 🙌&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://papers.labml.ai/papers/daily/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;DAILY PAPERS&lt;/a&gt;
: 최신 인기있는 AI 논문을 찾아주는 웹 사이트입니다.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/c/YannicKilcher/videos&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;YannicKilcher youtube&lt;/a&gt;
: 최신 AI 기술을 요약하여 설명해주는 유튜브 채널입니다.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/MachineLearning/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Reddit, ML 카테고리&lt;/a&gt;
: AI 관련 소식을 공유하는 커뮤니티입니다.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/newsletter&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Papers with Code, 뉴스레터&lt;/a&gt;
: 최신 인기있는 AI 자료들을 공유해주는 뉴스레터입니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-to-post&#34;&gt;How to post&lt;/h3&gt;
&lt;p&gt;&lt;img  src=&#34;https://cse-study.github.io/assets/img/notice1.png&#34;
        alt=&#34;img&#34;/&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;+++
&lt;span class=&#34;nv&#34;&gt;title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;제목을 입력하세요.&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;date&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;2022-01-01&amp;#34;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;profile&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
	&lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
	&lt;span class=&#34;nv&#34;&gt;avatar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;/assets/img/profile.jpg&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;nv&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;홍길동&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;nv&#34;&gt;email&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;hong-gildong@gmail.com&amp;#34;&lt;/span&gt;
+++

포스팅의 미리보기 입니다.
&amp;lt;!--more--&amp;gt;

&amp;lt;mark&amp;gt;본문입니다.&amp;lt;/mark&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;마크다운 파일의 제목은 &lt;code&gt;작성날짜-제목.md&lt;/code&gt;의 형태로 설정해주시면 좋습니다.&lt;/li&gt;
&lt;li&gt;각 스터디의 github repository에 마크다운 파일을 push하여 블로그에 포스팅을 업로드 할 수 있습니다.&lt;/li&gt;
&lt;li&gt;💡 &lt;code&gt;Notice&lt;/code&gt;: 자동화가 아직 적용되지 않았습니다. 배포까지의 자세한 과정은 관리자에게 문의해주세요!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;image-upload&#34;&gt;Image upload&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;프로필 이미지 업로드 방법은 다음과 같습니다. (아직 작성하지 않았습니다.)&lt;/li&gt;
&lt;li&gt;게시글 이미지 업로드 방법은 다음과 같습니다. (아직 작성하지 않았습니다.)&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Hello 👋</title>
      <link>https://cse-study.github.io/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/home/</guid>
      <description>&lt;p&gt;안녕하세요, 방문해주셔서 감사합니다. 저희는 이 곳에서 CS 관련 스터디를 진행하고 있습니다. 현재는 알고리즘/코테 스터디와, 간단한 AI 스터디를 진행하고 있습니다!&lt;/p&gt;
&lt;h3 id=&#34;weekly-ai&#34;&gt;Weekly AI&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AI 관련 소식, 기술 블로그 글, 유튜브 영상 등 관심있는 자료를 보고 &lt;mark&gt;간단히 요약&lt;/mark&gt;합니다. 느낀점, 한줄평을 추가해주셔도 좋습니다.&lt;/li&gt;
&lt;li&gt;게시글은 &lt;mark&gt;매주 1인당 1개씩 작성&lt;/mark&gt;합니다. 최신 AI 기술을 파악하는 것이 목적이므로 2년 이내의 자료만 허용합니다.&lt;/li&gt;
&lt;li&gt;어떤 자료를 참고하였는지 다른 사람들도 확인할 수 있도록 &lt;mark&gt;참고한 자료의 링크를 reference&lt;/mark&gt; 달아주시면 좋습니다.&lt;/li&gt;
&lt;li&gt;유명하거나, 임팩트있는 기술이 아니어도 상관 없으며, 각자 관심있는 분야의 AI 소식을 매 주 받아들이면서 서로의 시야가 넓어지는 것이 스터디의 주요 목표입니다.&lt;/li&gt;
&lt;li&gt;서로의 게시글에서 궁금한 점이 있다면 적극적으로 코멘트 해주세요!&lt;/li&gt;
&lt;li&gt;항상 저작권 문제를 고려하며 게시글을 작성해주시면 감사하겠습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;알고리즘 스터디는 스터디 원 모두 같은 주제의 문제를 푸는 &lt;mark&gt;공동 목표&lt;/mark&gt;와 개별적으로 하고 싶은 공부를 진행하는 &lt;mark&gt;개인 목표&lt;/mark&gt;로 이루어 집니다.&lt;/li&gt;
&lt;li&gt;공동 목표는 매주 1개의 주제에 대해서 알고리즘 사이트 문제 중에서 2문제를 푸는 것을 목적으로 하며 &lt;a href=&#34;https://github.com/cse-study/algorithm-code&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&lt;code&gt;algorithm-code&lt;/code&gt;&lt;/a&gt;
 저장소에 풀이 코드를 제출합니다.&lt;/li&gt;
&lt;li&gt;개인 목표는 알고리즘/코딩 테스트 관련 주간 목표를 개별적으로 설정하고 수행합니다(e.g. 알고리즘 글 포스팅, 코딩 인터뷰 문/답, 추가 알고리즘 사이트 문제 풀이, 등). 개인 목표의 결과물이 글의 형태라면 블로그 Algorithm 카테고리에 포스팅 해주시면 좋습니다.&lt;/li&gt;
&lt;li&gt;더욱 자세한 내용은 &lt;a href=&#34;https://github.com/cse-study/algorithm-code&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;링크&lt;/a&gt;
를 참고해주세요.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;contributors&#34;&gt;Contributors&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;🚀 &lt;a href=&#34;https://github.com/yuhodots&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;yuhodots&lt;/a&gt;
: 갓생을 꿈꾸는 대학원생입니다.&lt;/li&gt;
&lt;li&gt;🐢 &lt;a href=&#34;https://github.com/jiun0&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;jiun0&lt;/a&gt;
: Bandit 알고리즘과 추천 시스템을 연구하고 있는 대학원생입니다. 코딩조아.&lt;/li&gt;
&lt;li&gt;🙂 &lt;a href=&#34;https://github.com/bwmelon97&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;bwmelon97&lt;/a&gt;
: 졸업을 앞둔 복학생입니다. 원거리 딜러(AD carry)를 전문으로 하고 있습니다.&lt;/li&gt;
&lt;li&gt;👻 &lt;a href=&#34;https://github.com/minjae-lulu&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;minjae-lulu&lt;/a&gt;
: 동형암호를 공부하고 있는 학생입니다.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>