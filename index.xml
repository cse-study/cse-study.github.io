<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS Study Group</title>
    <link>https://cse-study.github.io/</link>
    <description>Recent content on CS Study Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>©2019 Notepadium.</copyright>
    <lastBuildDate>Tue, 22 Mar 2022 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://cse-study.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Big-O notation</title>
      <link>https://cse-study.github.io/algorithm/2022-03/220322-big-o-notation/</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/algorithm/2022-03/220322-big-o-notation/</guid>
      <description>&lt;p&gt;2022년 03월 2주차 개인 목표 수행합니다.&lt;/p&gt;
&lt;p&gt;학계와 산업계에서 말하는 big-O notation에는 약간의 차이가 존재한다는 것을 알게 되었음. 이전부터, 수업에서 배우는 big-O와 일반적으로 널리 쓰이는 big-O의 의미가 다르다는 점이 헷갈렸는데, 해당 챕터를 읽고 이해할 수 있게 되었음&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(시간복잡도의 경우) 학계에서 big-O는 시간의 상한, big-$\Omega$(omega)는 등가 혹은 하한, big-$\Theta$(theta)는 O와 $\Theta$ 둘 다를 의미함&lt;/li&gt;
&lt;li&gt;따라서 O($N$)으로 표현되는 알고리즘을 O($N^2$), O($N^3$), O($2^N$)으로도 표현하는 것이, 학계에서는 옳은 표현임&lt;/li&gt;
&lt;li&gt;하지만 산업계에서(면접에서) 말하는 big-O의 의미는 학계에서의 $\Theta$의 의미와 가깝다고 생각하면 된다고 함&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;추가적으로, 공간복잡도는 시간이 아닌 메모리(혹은 공간)을 big-O로 표현한 것임&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>면접 준비 과정</title>
      <link>https://cse-study.github.io/algorithm/2022-03/220322-%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8-%E1%84%8C%E1%85%AE%E1%86%AB%E1%84%87%E1%85%B5-%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A5%E1%86%BC/</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/algorithm/2022-03/220322-%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8-%E1%84%8C%E1%85%AE%E1%86%AB%E1%84%87%E1%85%B5-%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A5%E1%86%BC/</guid>
      <description>&lt;p&gt;Cracking the coding interview 58p까지 읽고 유용했던 내용을 공유합니다. &amp;lt;해외 기업의 채용 절차&amp;gt;와 &amp;lt;지원 전에 준비할 점&amp;gt;에 대한 내용 위주로 느낀점을 공유합니다.&lt;/p&gt;
&lt;p&gt;아무래도 대기업이다보니 중요한 역량은 대부분 일치한다는 것을 알 수 있었는데, 회사마다의 조금씩 다른 특징도 엿볼 수 있었음.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;면접은 보통 전화 통화와 같은 사전 면접 이후에, 3~6번 정도의 대면 면접으로 이루어짐&lt;/li&gt;
&lt;li&gt;마이크로소프트: 괴짜로 불리는 사람들을 원한다(?)고 함. 면접관들이 일하는 곳에서 면접을 본다는 점이 신선했음. 팀 마다 방향이 달라서 어느 팀에 가게 되느냐에 따라 경험이 크게 달라진다고 함&lt;/li&gt;
&lt;li&gt;아마존: 규모 확장성(scalability)에 신경을 많이 쓰며, 객체 지향 디자인에 대해 질문을 많이 하는 경향이 있다고 함.&lt;/li&gt;
&lt;li&gt;구글: 마소, 아마존과 크게 다르지 않으며, 웹 기반으로 시작했기 때문에 구글 또한 규모 확장성에 관심이 많다고 함. 특히 과거 경력에 관계 없이 알고리즘 능력에 큰 비중을 두기 때문에 이 점을 잘 준비해야 함&lt;/li&gt;
&lt;li&gt;페이스북: 개발자 또한 기업가 정신을 갖기를 원하니, 무엇이든 빠르게 결과 내는 사람이라면 좋다고 함&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;면접 전에 갖춰야 할 역량이나 경험에 대해서 다음과 같은 조언도 얻을 수 있었음&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;아직 학생이라면, 큰 규모의 프로젝트 수업을 듣거나 / 인턴 자리를 알아보거나 / 뭔가(프로젝트)를 하라고 함&lt;/li&gt;
&lt;li&gt;이력서는 짧을수록 인상에 남으며, 미국에서는 경력이 십 년 미만인 경우 한 페이지의 이력서를 권장한다고 함&lt;/li&gt;
&lt;li&gt;특정 언어를 사용하는게 낙인이 될 수도 있고, 한 두가지 언어만 알고 있는 경우 구인 담당자가 지원자에 대해 아직 많은 문제를 경험해 보지 못한 사람으로 간주할 수 있다고 함&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;나의 경우엔 현재 모든 작업을 python으로 하고 있는데, 실제 서비스에서는 아무래도 속도가 중요하다보니 C/C++도 가까이 해야겠다는 생각이 들었음&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Self-supervised continual learners</title>
      <link>https://cse-study.github.io/ai/2022-03/220321-self-supervised-coninual-learner/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/220321-self-supervised-coninual-learner/</guid>
      <description>&lt;p&gt;최근 1년간 진행된 continual learning 연구 중에서 self-supervised approach를 사용한 논문들에 대해서 간단히 정리합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&amp;ldquo;Co2l: Contrastive continual learning.&amp;rdquo; ICCV 2021&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Asymmetric SupCon loss로 새로운 지식을 학습(novel learning)하고, self-supervised instance-wise relation distill(IRD)로 과거의 지식을 보존(prevent forgetting)&lt;/li&gt;
&lt;li&gt;Asymmetric SupCon: contrastive learning에 current task examples와 memory buffer examples를 둘 다 사용하지만, anchor로는 current task examples만 사용. 이렇게 하면 단순히 contrastive learning 하는 것 보다 효과 좋음&lt;/li&gt;
&lt;li&gt;IRD: reference(previous) model output과 동일해지도록 현재 모델 regulate (2N개 examples에 대해 전부)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ldquo;How Well Does Self-Supervised Pre-Training Perform with Streaming ImageNet?.&amp;rdquo; NeruIPS 2021&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised learning 방식으로 pre-training하면, streaming data에 대해서 joint training(non-streaming) 만큼의 성능이 나온다는 것을 주장&lt;/li&gt;
&lt;li&gt;Pre-training은 MoCo-v2 protocol을 따르고, OpenSelfSup 라는 prior works의 구현을 기반으로 하였음&lt;/li&gt;
&lt;li&gt;Streaming data의 distribution shift가 조금인 경우에는 joint training과 self-supervised pre-training의 성능이 거의 비슷하고, large distribution shift인 경우에는 MAS(memory aware synapse)와 data replay 방법을 사용하면 비슷해짐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;ldquo;Rethinking the Representational Continuity: Towards Unsupervised Continual Learning.&amp;rdquo; ICLR 2022&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Label unannotated인 unsupervised continual learning(CURL)을 SimSiam과 Barlow Twining라는 prior works 알고리즘 사용하여 해결해보았더니 신기하게도 supervised continual learning보다 catastrophic forgetting에 강건함&lt;/li&gt;
&lt;li&gt;Lifelong Unsupervised Mixup(LUMP)는 previous task(in memory buffer)와 current task 사이의 interpolate를 활용하는 방법이며, LUMP를 안 써도 잘하지만 LUMP를 사용하면 더 잘함&lt;/li&gt;
&lt;li&gt;Unsupervised continual learning과 supervised continual learning이 low layer에서는 similar하고 high layer에서는 dissimilar함. Unsupervised continual learning의 loss landscape이 더 smooth 함&lt;/li&gt;
&lt;li&gt;Test 단계에서 classifying은 KNN을 사용한다고 하는데, 어떻게 사용한건지 아직 제대로 살펴보진 않았음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised learning이 좋은 representation을 학습한다는 점, 그리고 새로운 지식을 추가적으로 배우는 경우 중에서 특히 해당 데이터의 양이 적을 때 더 효과적이라는 것이 이미 실험적으로 알려져 있었음. 이 장점은 continual learning이 풀고자 하는 문제와 일치하므로 self-supervised learning 방식이 continual learning task에서 효과적일 것이라는 점은 어느정도 예상된 일이었음&lt;/li&gt;
&lt;li&gt;따라서 매우 많은 연구자들이 동시에 해당 문제를 거의 비슷한 방식으로 접근했다는 것이 인상적임&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2021/html/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.html&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Cha, Hyuntak, Jaeho Lee, and Jinwoo Shin. &amp;ldquo;Co2l: Contrastive continual learning.&amp;rdquo; ICCV 2021.&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openreview.net/pdf?id=gYgMSlZznS&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Hu, Dapeng, et al. &amp;ldquo;How Well Does Self-Supervised Pre-Training Perform with Streaming ImageNet?.&amp;rdquo; NeruIPS 2021.&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openreview.net/pdf?id=9Hrka5PA7LW&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Madaan, Divyam, et al. &amp;ldquo;Rethinking the Representational Continuity: Towards Unsupervised Continual Learning.&amp;rdquo; ICLR 2022.&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>DopNet</title>
      <link>https://cse-study.github.io/ai/2022-03/20220312-dopnet/</link>
      <pubDate>Sat, 12 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/20220312-dopnet/</guid>
      <description>&lt;p&gt;한국화학연구원에서 2021년 7월에 nature computational materials에 발표한 “Predicting thermoelectric properties from chemical formula with explicitly identifying dopant effects”를 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;p&gt;이전 포스팅도 참고 하시면 좋습니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;머신 러닝은 소재 분야에서 많이 쓰이고 있습니다. 만들고자 하는 소재의 물성을 예측하고 어떻게 해야 원하는 특징을 가진 소재를 개발할 수 있을지 도움을 얻을 수 있기 때문입니다.&lt;/li&gt;
&lt;li&gt;하지만 기존 방법들은 도핑된 물질에 대해선 정확한 특성 예측이 힘들어 전문가의 직관에 의존해 개발이 이루어졌습니다. 한국화학연구원은 이 문제를 해결하기 위한 알고리즘을 개발했고 DopNet이라 이름지었습니다.&lt;/li&gt;
&lt;li&gt;기존 알고리즘의 문제는 크게 다음과 같습니다.
&lt;ul&gt;
&lt;li&gt;도핑된 재료의 결정 구조를 찾는데 너무 많은 계산이 필요하다.&lt;/li&gt;
&lt;li&gt;Dopants는 전체에서 낮은 비율을 차지하기 때문에 화학식을 기반으로 한 물질 표현은 해당 효과를 잘 나타내지 못한다(수치적 변화가 크지 않음).&lt;/li&gt;
&lt;li&gt;Dopants가 극적으로 host material의 성질을 바꿀 때 비선형이 크게 나타난다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;이를 해결하기 위해 DopNet은 결정 구조 계산 없이 재료 특성을 예측할 수 있도록 만들었습니다. 그리고 host material과 dopant를 명시적으로 나누어 임베딩하였습니다(기존 방법에서는 dopant 식별 여부와 관계 없이 재료 원자들에 대한 원소 통계 정보만 이용한 것으로 보입니다).&lt;/li&gt;
&lt;li&gt;DopNet은 세 부분으로 구성되어 있습니다.
&lt;ul&gt;
&lt;li&gt;Host material 잠재 임베딩을 추출하는 호스트 임베딩 네트워크&lt;/li&gt;
&lt;li&gt;Dopants 잠재 임베딩을 생성하는 dopants 임베딩 네트워크&lt;/li&gt;
&lt;li&gt;Host material과 dopants의 임베딩을 통해 재료 특성을 예측하는 dense 네트워크&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DopNet이 작동하는 단계는 다음과 같습니다.&lt;/li&gt;
&lt;li&gt;화학식이 입력되면 이는 host material과 dopants로 분해됩니다. 재료의 각 원자는 비율이 γ보다 작거나 같을 때 dopants로 분류되며, γ≥0은 DopNet에 미리 정의되어 있는 hyperparameter입니다.&lt;/li&gt;
&lt;li&gt;Host material는 원소 통계 정보를 기반으로 $\mathbf{x}_h$ 벡터로 표현됩니다. 호스트 특징 벡터에 인코더가 적용되고 호스트 임베딩 네트워크를 통과해 호스트 임베딩이 계산됩니다.&lt;/li&gt;
&lt;li&gt;Dopants의 특징 벡터는 최대 K개의 dopants를 포함할 수 있는 집합 $S_d$에 저장됩니다. 여기서 K는 hyperparameter입니다. Dopants는 dopant 임베딩 네트워크를 통해 임베딩되고 생성된 dopant 임베딩은 단일 벡터 $\mathbf{z}_d$로 표현됩니다.&lt;/li&gt;
&lt;li&gt;마지막으로 dense network를 통해 물성 $\mathbf{y}$ 를 예측합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img  src=&#34;https://cse-study.github.io/assets/img/DopNet_architecture.png&#34;
        alt=&#34;DopNet_architecture&#34;/&gt;&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이론 분야를 공부하고 있지만 실제 세상의 문제를 해결하기 위해 어떤 노력들과 아이디어도 흥미롭습니다. 특히 학부 전공과 관련된 내용들이다 보니 더 재미있게 읽었습니다.&lt;/li&gt;
&lt;li&gt;내가 하는 연구나 공부가 실제로 어떻게 적용되어 어떤 문제를 해결하고 다른 이들의 연구와 인간의 삶에 어떤 영향을 미칠지 생각하거나 찾아 보는 것도 좋다고 생각합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ngs00/DopNet&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/ngs00/DopNet&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s41524-021-00564-y&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.nature.com/articles/s41524-021-00564-y&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>POMO: Policy Optimization with Multiple Optima for Reinforcement Learning</title>
      <link>https://cse-study.github.io/ai/2022-03/220306-pomo/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/220306-pomo/</guid>
      <description>&lt;p&gt;Samsung SDS Techtonic의 &amp;ldquo;POMO: 강화학습을 이용한 조합 최적화(NeurIPS 2020)&amp;rdquo; 발표를 보고 느낀점을 공유합니다. 해당 자료는 reference로 걸어두었습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;조합최적화 문제를 강화학습으로 풀려는 시도들이 최근 많이 있음&lt;/li&gt;
&lt;li&gt;강화학습을 처음 공부할 때는 강화학습이 풀 수 있는 실제 세상의 문제가 많이 있을지 의문이었는데, 실제 세상에서 적용할 수 있지만 아직 사람들이 가치를 발견하지 못한 경우가 많겠다는 생각이 들었음&lt;/li&gt;
&lt;li&gt;조합 최적화를 들어보긴 했지만 실제로 어떤 내용인지는 영상을 통해 처음으로 접했음. 내용이 흥미로워서 기초부터 주요 논문까지 쭉 순서대로 제대로 공부해보고 싶다는 생각이 들었음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Dyp9lQpVgCs&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;[Techtonic 2020] Track 1. POMO: 강화학습을 이용한 조합 최적화(NeurIPS 2020) - 권영대 프로&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=hAirBRQSFm0&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;[Techtonic 2021] AI를 사용해 기업의 조합최적화 작업을 처리할 수 있을까? (NeurIPS 2021) - 권영대 프로&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper/2020/hash/f231f2107df69eab0a3862d50018a9b2-Abstract.html&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;POMO: Policy Optimization with Multiple Optima for Reinforcement Learning&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ChemAI</title>
      <link>https://cse-study.github.io/ai/2022-03/20220305-chemai/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-03/20220305-chemai/</guid>
      <description>&lt;p&gt;2021년 8월 한국화학연구원에서 발표한 ChemAI와 관련된 자료들을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;화학, 소재 분야에서도 최근 머신 러닝을 이용한 연구들이 많이 진행되고 있습니다. 분자가 어떤 특성을 가질지, 원하는 성질을 갖는 분자 구조를 어떻게 디자인 할 것인지, 어떻게 합성 과정을 최적화할지 등 여러 방면으로 머신 러닝을 활용할 수 있습니다. 벌써 네이처 퍼블리싱 그룹의 10% 정도가 머신 러닝과 관련된 연구라고 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;하지만 화학 분야에서 이를 적용하기에는 어려움 또한 따릅니다. 연구 환경을 세팅하는 것이 복잡하게 느껴질 수 있으며 SMILES 등 구조적인 관계를 나타내는 데이터를 수치적으로 바꿔야 해서 데이터 전처리가 쉽지만은 않습니다. 또한 화학 분야 전문가들이 생소한 머신러닝 알고리즘에 대해 공부하고 하이퍼 파라미터 최적화와 evaluation까지 진행하려면 많은 시간과 노력이 필요할 것입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;한국화학연구원은 이를 해결하기 위해 ChemAI를 만들었습니다. ChemAI는 웹 베이스이기 때문에 누구나 쉽게 접근이 가능합니다. 자동으로 데이터를 수치 데이터로 변환하고 적합한 알고리즘을 선택해 줍니다(연구 목적이나 물질에 따라 알고리즘을 선택하는 것은 매우 중요합니다. 머신 러닝이 아닌 기존 DFT(density functional theory) 시뮬레이션에서도 물질이 crystal인지, 금속인지, 반도체인지, 단백질인지 등에 따라 다른 프로그램과 방법을 사용합니다). 이후 자동으로 hyperparameter 최적화와 evaluation, visualization까지 진행해 줍니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;알고리즘은 crystal GNN(소재 분야 SOTA), symbolic regression, 화학연구원에서 자체 개발한 DopNet 등 총 16가지가 제공됩니다. SMILES 구조의 성질을 예측하는 데는 GNN을 사용했고 crystal structure의 경우 mendeleev, pytorch geometric 등을 이용했다고 합니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;머신 러닝은 여러 분야에서 문제를 더 쉽고 빠르게 해결할 수 있는 방법이 될 수 있습니다. 하지만 이를 활용하는 것이 쉽지는 않기 때문에 문제 해결의 선택지에서 고려되지 않는 경우도 많습니다.&lt;/li&gt;
&lt;li&gt;따라서 ChemAI와 같이 누구든지 쉽게 이용 가능하도록 만든 머신 러닝 툴의 역할과 의미가 매우 크다고 생각합니다. 이는 화학 분야에 종사하는 사람들의 시간과 노력을 아껴주고 새로운 발견을 해 낼 가능성을 높여줄 것입니다.&lt;/li&gt;
&lt;li&gt;화학공학과 컴퓨터 공학을 전공하다가 처음 머신 러닝에 관심을 가지게 된 이유도 이러한 맥락이었습니다. 지금은 여러 이유로 조금은 다른 길을 가고 있기는 하지만 언젠가 이런 프로그램을 만들어 보고 싶네요.&lt;/li&gt;
&lt;li&gt;DopNet에 대해서도 다루려고 했는데 글이 길어져서 다음 주에 다룰 예정입니다. 관심이 있으시면 “Predicting thermoelectric properties from chemical formula with explicitly identifying dopant effects” 를 읽어 보시길 바랍니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Q7vL1rSG-pk&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.youtube.com/watch?v=Q7vL1rSG-pk&lt;/a&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Magnetic control of tokamak plasmas</title>
      <link>https://cse-study.github.io/ai/2022-02/20220227-magnetic-control-of-tokamak-plasmas/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/20220227-magnetic-control-of-tokamak-plasmas/</guid>
      <description>&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;딥마인드와 스위스 로잔연방공대 플라즈마 센터가 심층 강화학습을 이용해 토카막에서의 플라즈마 제어를 성공적으로 수행했다. 이는 네이처 2022.2월 호에 게재되었다.&lt;/li&gt;
&lt;li&gt;플라즈마 제어를 위한 코일 전류의 조절은 선형화된 모델을 기반으로 한다. 하지만 이는 복잡한 실시간 계산이 필요하며 목표 플라즈마 구성이 변경될 때마다 상당한 공학적, 설계적 노력을 기울여야 한다. 따라서 비선형 컨트롤러를 생성하고 제어를 용이하게 하기 위해 심층 강화학습을 도입하였다.&lt;/li&gt;
&lt;li&gt;실험 목표는 시간 변화에 따른 원하는 제어 값 등으로 설정했다. Extended Table 4에서 찾아볼 수 있다. 학습은 토카막 시뮬레이터와의 상호 작용을 통해 이루어지며 제어 정책은 하드웨어에서 실시간으로 직접 실행된다(제로 샷).&lt;/li&gt;
&lt;li&gt;하지만 지속적으로 변하는 플라즈마 상태를 계산해야 하기 때문에 시뮬레이터에서 공급되는 데이터 속도는 일반적인 강화학습 환경에 비해 매우 느리다. 이 문제는 maximum a posteriori policy optimization(MPO)를 적용하여 극복했다고 한다.&lt;/li&gt;
&lt;li&gt;플라즈마 제어를 위한 모델에서 중요한 점은 정해진 시간 안에 빠르게 실행이 가능해야 한다는 것이다. 해당 실험에서 쓰인 TCV의 경우 50us라는 시간이 사용 가능했다. 이를 맞추기 위해 불필요한 것들을 제외하고, tfcompile 등을 이용한 바이너리 컴파일 등 여러 방면으로 최적화를 하였다.&lt;/li&gt;
&lt;li&gt;결과적으로 19개 자기 코일로 이루어진 토카막을 한 번에 제어할 수 있는 간결한 제어 환경을 구축하였고 원하는 플라즈마 모양을 시간에 따라 잘 제어할 수 있었다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;단순히 시뮬레이팅이나 이론으로 끝나는 것이 아닌 실제 환경에 적용하여 좋은 결과를 냈다는 점이 유의미하다고 생각한다.&lt;/li&gt;
&lt;li&gt;완전히 새로운 알고리즘을 제안했다기 보다는 실제 적용을 위해 많은 엔지니어링적 노력을 한 것 같다. 제한된 시간 안에 작동하도록 한 것과 제로 샷으로 좋은 성과를 얻은 것이 특히 더 대단해 보인다.&lt;/li&gt;
&lt;li&gt;MPO에 대해 공부해 봐야겠다..&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s41586-021-04301-9&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.nature.com/articles/s41586-021-04301-9&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>OpenAI Embeddings API</title>
      <link>https://cse-study.github.io/ai/2022-02/220227-openai-embeddings/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/220227-openai-embeddings/</guid>
      <description>&lt;p&gt;2022년 1월에 OpenAI에서 발표한 &amp;ldquo;Text and Code Embeddings by Contrastive Pre-Training&amp;rdquo; 논문의 관련 자료들을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OpenAI에서 GPT-3의 text (or code) embedding 결과를 쉽게 얻을 수 있도록 돕는 Embeddings API라는 툴을 공개함&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;입력 text(or code)와 엔진 이름을 입력하면, 해당 입력의 vector representation(embedding)을 얻을 수 있음&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;openai&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Embedding&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;canine companions say&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;text-similarity-davinci-001&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;관련하여 3가지 대표적인 use-cases(: Text Similarity, Text Search, Code Search)를 제공함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;편의를 위해 &lt;code&gt;delicious beans&lt;/code&gt;과 같이 N개의 단어 조합으로 이루어진 Embeddings API 입력 text를 &amp;lsquo;쿼리&amp;rsquo;라고 칭하겠음. Text similarity는 두 개의 쿼리에 대해 API를 사용하여 유사도를 구하는 작업이고, Text Search는 주어진 쿼리에 대해 가장 유사도가 높은 도큐먼트를 데이터 셋 내에서 찾아내는 (쿼리와 도큐먼트 사이의 유사도를 구하는) 작업이고, Code Search는 주어진 쿼리에 대해 가장 유사도가 높은 함수(혹은 코드)를 데이터 셋 내에서 찾아내는 작업이라고 생각하면 됨.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;링크&lt;/a&gt;
에 따르면, Embeddings API는 논문에서 말하는 것 처럼 성능이 현재 다른 모델들 대비 그렇게 좋은 것은 아니고, 모델과 feature dimension이 매우 커서 cost가 너무 높고, 토큰당 가격도 너무나 비싸다고 말하고 있음. (Davinci 모델의 경우 12288 dimensions을 사용하고 토큰당 0.6달러이기 때문에, 일반 유저가 사용하는 것은 거의 불가능하지 싶음)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI Blogs, &lt;a href=&#34;https://openai.com/blog/introducing-text-and-code-embeddings/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&amp;ldquo;Introducing Text and Code Embeddings in the OpenAI API&amp;rdquo;.&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Yannic Kilcher YouTube, &lt;a href=&#34;https://www.youtube.com/watch?v=5skIqoO3ku0&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&amp;ldquo;OpenAI Embeddings (and Controversy?!)&amp;rdquo;.&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenAI Embeddings API: &lt;a href=&#34;https://beta.openai.com/docs/guides/embeddings&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://beta.openai.com/docs/guides/embeddings&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Nils Reimers, &lt;a href=&#34;https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;&amp;ldquo;OpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?&amp;quot;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Data2Vec</title>
      <link>https://cse-study.github.io/ai/2022-02/220218-data2vec/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/220218-data2vec/</guid>
      <description>&lt;p&gt;2022년 1월에 Meta AI에서 발표한 &lt;strong&gt;Data2vec&lt;/strong&gt; 블로그 포스팅을 읽고 내용을 공유합니다.&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;현재의 self-supervised learning 연구들은 image, speech, text 등 각기 다른 modality마다 학습 방법에 차이가 크다.&lt;/li&gt;
&lt;li&gt;따라서 Meta AI는 multiple modality(e.b. image, speech, text)에서 작동하는 data2vec을 개발하였으며, data2vec은 기존 computer vision, speech 분야의 알고리즘 성능을 넘었고, NLP 분야에서는 견줄만큼의 성능을 기록하였다.&lt;/li&gt;
&lt;li&gt;Data2vec은 기존에 self-supervised learning에서 자주 사용되던 contrastive learning이나, reconstructing the input example 방식을 사용하지는 않는다.&lt;/li&gt;
&lt;li&gt;Data2vec은 input data에 대한 own representation을 맞추도록 학습시킨다.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Teacher network에 데이터를 넣어 출력된 representation을 target으로 설정한다.&lt;/li&gt;
&lt;li&gt;Student network에는 데이터에 일부 masking을 가해서 넣어 representation을 얻어내고, 이 representation이 teacher의 target representation과 동일해지도록 모델을 학습시킨다.&lt;/li&gt;
&lt;li&gt;Teacher와 student는 동일한 네트워크이지만 weight 값이 살짝 다르다. (&lt;a href=&#34;https://yuhodots.github.io/deeplearning/21-04-04/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;BYOL&lt;/a&gt;
 처럼 exponentialmoving average 사용)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised learning 중에서도 BYOL의 아이디어를 차용하여 multi-modal learning 알고리즘을 고안한 것이 재미있었음&lt;/li&gt;
&lt;li&gt;하나의 backbone으로 image, speech, text 관련 task에 모두 적용 가능하다는 것이, 현재까지의 multi-modal 연구 중에 가장 자연스러운 방법이라는 생각이 들며 future work들이 기대됨&lt;/li&gt;
&lt;li&gt;Label이 필요없고, multi-modality에서 작동하고, single-purpose algorithms보다 잘하는 AI 모델. 이것이 앞으로의 AI의 주요 방향성이 되지 않을까 싶음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Data2vec블로그 포스팅: &lt;a href=&#34;https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text/&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;The first high-performance self-supervised algorithm that works for speech, vision, and text&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Data2vec paper: &lt;a href=&#34;https://ai.facebook.com/research/data2vec-a-general-framework-for-self-supervised-learning-in-speech-vision-and-language&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;Data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Data2vec code: &lt;a href=&#34;https://github.com/pytorch/fairseq/tree/main/examples/data2vec&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://github.com/pytorch/fairseq/tree/main/examples/data2vec&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>GT Sophy</title>
      <link>https://cse-study.github.io/ai/2022-02/20220214-gt-sophy/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cse-study.github.io/ai/2022-02/20220214-gt-sophy/</guid>
      <description>&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;
&lt;img src=&#34;https://media.springernature.com/w200/springer-static/cover-hires/journal/41586/602/7896&#34; alt=&#34;Volume 602 Issue 7896&#34; style=&#34;zoom:100%; display: block; margin-left: auto; margin-right: auto;&#34; /&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;2022년 2월 소니 AI가 개발한 자동차 경주 AI가 네이처 표지를 장식했음. 게임 이름은 그란 투스리모 스포츠임.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;인공지능 이름은 GT Sophy. Model free, off-policy deepRL을 이용했음. Distributional SAC과 비슷하지만 value backup 과 target functions가 다른 QR-SAC을 이용했다고 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;게임의 리얼리즘 때문에 생각보다 어려웠다고 함. 또한 규정화되어 있지 않은 스포츠맨십을 지키며 너무 공격적이지도 소극적이지도 않게 플레이 하기 위한 보상 체계를 만드는 것이 힘들었다고 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;학습 방법: PS4에서 실행되는 GT인스턴스를 제어하는 rollout worker에게 트레이닝 시나리오를 배포하면 각 agent는 가장 최근 policy의 사본을 실행시키고 action을 전송함. 비동기적으로 다음 프레임을 계산해 새로운 상태를 알아냄. State, action, reward 튜플을 ERB에 저장함. 트레이너는 policy를 업데이트하기 위해 ERB를 샘플링함.&lt;/p&gt;
&lt;img src=&#34;https://cse-study.github.io/assets/img/image-20220214181447986.png&#34; alt=&#34;image-20220214181447986&#34; style=&#34;zoom:30%; display: block; margin-left: auto; margin-right: auto;&#34; /&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;강화학습을 이용해 게임에 적용시키는 경우가 점점 늘어나는 것 같음. 적용시키기 좋고, 흥미로우며 이슈도 되기 때문이라 생각함. 개인적으로도 해 보고 싶다는 생각이 들었음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AI vs 사람 구도의 실험에서는 AI와 사람 간 공평성을 위한 적절한 방법들이 고려되어야 함. 예를 들어 알파스타의 경우 평균 APM에 제한을 두었지만 중요한 교전 상황에 압도적인 순간 APM을 보이며 승리했음. 사람의 경우 APM이 모두 의미 있는 동작을 뜻하지 않으므로 실제 차이는 더 컸었다 해석할 수 있음. 해당 실험에서도 여러 사항을 고려하여 제약을 두었음. 논문의 Fairness versus humans에서 찾아볼 수 있음.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;개발진들이 이런 연구를 하는 이유는 사람과 싸워 이기는 AI를 만들기 위함이 아니라 사람을 더 잘 이해하고, 더 재미있으며 흥미로운 탐험과 새로운 경험을 사용자에게 제공하기 위함이라 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;연구의 의미를 항상 생각하는 것이 중요함을 다시 한 번 느꼈음. 새로운 방법과 좋은 성능 자체도 의미있지만 이들이 앞으로의 연구와 우리의 삶에 어떤 긍정적인 역할을 할지 깊게 생각한다면 더 좋을 것 같다는 생각을 했음.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s41586-021-04357-7&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://www.nature.com/articles/s41586-021-04357-7&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/l948hMaTPuo&#34;target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34;&gt;https://youtu.be/l948hMaTPuo&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>