<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.92.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Vision Transformer&nbsp;&ndash;&nbsp;CS Study Group</title><link rel="stylesheet" href="/css/core.min.8ea708522f75bfcc8135986b9fdcb802f298c946aff4776dc7b9f03a02ba7f8767f76ca0e6523502305c2790e06cfb8f.css" integrity="sha384-jqcIUi91v8yBNZhrn9y4AvKYyUav9Hdtx7nwOgK6f4dn92yg5lI1AjBcJ5DgbPuP"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Vision Transformer" /><body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/home"><img class="site logo" src="/assets/img/logo.png" /><span class="site name">CS Study Group</span></a>
        </span>
        <span class="header right-side"><div class="nav wrap">
    <nav class="nav"><a class="nav item-main" href="/ai/"><span class="iconfont icon-ai"></span>Weekly AI</a>
        <a class="nav item-main" href="/algorithm/"><span class="iconfont icon-algo"></span>Algorithm</a>
        <a class="nav item-secondary" href="/help/"><span class="iconfont icon-algo"></span>Help</a>
    </nav>
</div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Vision Transformer</h1><p class="article date">Thursday, June 9, 2022</p></section><section class="article author">
    <div class='author-wrapper'>
        <div class='author-left'><img class="avatar" src="/assets/img/yuho.jpg" alt></div>
        <div class='author-right'><p class="name">Yuho Jeong</p><a class="item-email" href="mailto:yuho8437@unist.ac.kr" target="_blank" rel="noopener noreferrer">yuho8437@unist.ac.kr</a></div>
    </div>
</section><article class="article markdown-body"><p>Vision transformer와 DINO 논문에 대해, 관련 자료를 읽고 내용을 공유합니다.</p>
<h3 id="vision-transformer">Vision Transformer</h3>
<p><img  src="/assets/img/ViT.png"
        alt="img"/></p>
<center><p><i>Taken from Dosovitskiy, Alexey, et al.</i></p></center>
<ol>
<li>전체 이미지를 16 x 16 size의 patch로 절단. 예를 들어 48 x 48 이미지라면 9개의 patch로 나뉨
<ul>
<li>&ldquo;ViT-Base/16&rdquo; model에서 16이 의미하는 것이 patch size임</li>
</ul>
</li>
<li>각각의 patch를 평탄화(16 x 16 x 3 = 768) 한 뒤에, 워드 임베딩을 만드는 것 처럼 linear projection을 통해 embedding vector의 형태로 변환</li>
<li>해당 embedding vector에, BERT와 동일하게 CLS 토큰과 position embedding을 추가함. 이 둘은 learnable parameter 임
<ul>
<li>CLS 토큰은 patch embedding과 동일한 사이즈이며, 9개의 patch embedding들과 concat 함</li>
<li>position embedding은 총 9 + 1 = 10개로, patch embedding에 합(+)해주는 형태로 구성</li>
</ul>
</li>
<li>각 embedding vector를 하나의 워드 토큰으로 여겨, transformer의 입력으로 전달</li>
<li>BERT와 동일하게, CLS 토큰의 최종 출력이 해당 이미지의 output class라고 가정. 따라서 transformer 출력 단에서 CLS의 embedding이 어떻게 변했는지 확인하여 inference 수행</li>
</ol>
<h3 id="dino-self-distillation-with-no-labels">DINO (Self-<strong>di</strong>stillation with <strong>no</strong> labels)</h3>
<p><img  src="/assets/img/DINO.png"
        alt="img"/></p>
<center><p><i>Taken from Caron, Mathilde, et al.</i></p></center>
<ul>
<li>ViT를 <a href="https://yuhodots.github.io/deeplearning/21-04-04/"target="_blank" rel="noopener noreferrer">BYOL</a>
의 manner로 학습</li>
<li>BYOL과 달리 normalized embedding의 L2 distance를 사용하지는 않고, $p_2 \log p_1$ 형태의 cross entropy loss 사용</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training/"target="_blank" rel="noopener noreferrer">Advancing the state of the art in computer vision with self-supervised Transformers and 10x more efficient training</a>
</li>
<li>Dosovitskiy, Alexey, et al. &ldquo;An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.&rdquo; <em>International Conference on Learning Representations</em>. 2021.</li>
<li>Caron, Mathilde, et al. &ldquo;Emerging properties in self-supervised vision transformers.&rdquo; <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 2021.</li>
<li><a href="https://www.youtube.com/watch?v=h3ij3F3cPIk"target="_blank" rel="noopener noreferrer">Yanick Kilcher, &ldquo;DINO: Emerging Properties in Self-Supervised Vision Transformers (Facebook AI Research Explained)&quot;</a>
</li>
<li><a href="https://github.com/facebookresearch/dino"target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/dino</a>
</li>
</ul></article>
<section class="article discussion">
    <script src="https://utteranc.es/client.js" repo="cse-study/cse-study.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
    </script>
</section></div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/ai/2022-06/220603-open-world-learning/"><span class="iconfont icon-article"></span>Open-world Learning</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">©2019 Notepadium.</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank" rel="noopener noreferrer">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank" rel="noopener noreferrer">Notepadium</a></p></div>
</section><script defer type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-e/4/LvThKH1gwzXhdbY2AsjR3rm7LHWyhIG5C0jiRfn8AN2eTN5ILeztWw0H9jmN" crossorigin="anonymous"></script>
        <script
            type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script><script src="/js/hljs.min.72e76ccf211868d08e31d7ca45c02501991bd760f28809c52045fa79fb7b7428664bb54ae875b46031ebc760c77b9562.js" integrity="sha384-cudszyEYaNCOMdfKRcAlAZkb12DyiAnFIEX6eft7dChmS7VK6HW0YDHrx2DHe5Vi"></script><script>hljs.initHighlightingOnLoad();</script></body>

</html>