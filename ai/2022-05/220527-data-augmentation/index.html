<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.92.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Data Augmentation for Deep Learning&nbsp;&ndash;&nbsp;CS Study Group</title><link rel="stylesheet" href="/css/core.min.8ea708522f75bfcc8135986b9fdcb802f298c946aff4776dc7b9f03a02ba7f8767f76ca0e6523502305c2790e06cfb8f.css" integrity="sha384-jqcIUi91v8yBNZhrn9y4AvKYyUav9Hdtx7nwOgK6f4dn92yg5lI1AjBcJ5DgbPuP"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Data Augmentation for Deep Learning" /><body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/home"><img class="site logo" src="/assets/img/logo.png" /><span class="site name">CS Study Group</span></a>
        </span>
        <span class="header right-side"><div class="nav wrap">
    <nav class="nav"><a class="nav item-main" href="/ai/"><span class="iconfont icon-ai"></span>Weekly AI</a>
        <a class="nav item-main" href="/algorithm/"><span class="iconfont icon-algo"></span>Algorithm</a>
        <a class="nav item-secondary" href="/help/"><span class="iconfont icon-algo"></span>Help</a>
    </nav>
</div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Data Augmentation for Deep Learning</h1><p class="article date">Friday, May 27, 2022</p></section><section class="article author">
    <div class='author-wrapper'>
        <div class='author-left'><img class="avatar" src="/assets/img/yuho.jpg" alt></div>
        <div class='author-right'><p class="name">Yuho Jeong</p><a class="item-email" href="mailto:yuho8437@unist.ac.kr" target="_blank" rel="noopener noreferrer">yuho8437@unist.ac.kr</a></div>
    </div>
</section><article class="article markdown-body"><p>Deep Learning 모델 성능 개선을 위한 Data Augmentation 방법들과 효과를 정리합니다.</p>
<h3 id="mixup-iclr-2018">Mixup (ICLR 2018)</h3>
<ul>
<li><a href="https://arxiv.org/pdf/1710.09412.pdf"target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1710.09412.pdf</a>
</li>
<li>한 줄 요약: 두 개의 샘플에 대해서, input space와 output space를 각각 동일한 비율로 linear interpolate한 샘플 생성</li>
<li>장점/효과: Decision boundarie가 클래스에서 클래스로 선형적으로 변하기 때문에 더 smoother한 uncertainty estimation 제공</li>
</ul>
<h3 id="manifold-mixup-icml-2019">Manifold Mixup (ICML 2019)</h3>
<ul>
<li><a href="https://arxiv.org/abs/1806.05236"target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1806.05236</a>
</li>
<li>한 줄 요약: Itermediate layer의 representation을 mixup하는 방법</li>
<li>장점/효과: class-specific representations을 flatten하는 효과를 가짐. 그리고 이 flat representation에 대해서 학습때 보지 못했거나 data manifold를 벗어난 샘플은 low-confidence로 예측. 즉, 헷갈리는 샘플을 어떻게든 하나의 class로 할당하기 보다는, uncertainty 높은(어느 하나로 확신하지 않는) 예측을 뱉음</li>
</ul>
<h3 id="augmix-iclr-2020">AugMix (ICLR 2020)</h3>
<ul>
<li><a href="https://arxiv.org/pdf/1912.02781.pdf"target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1912.02781.pdf</a>
</li>
<li>한 줄 요약: 두 개의 샘플을 합치는 방법이 아닌, 하나의 샘플에 여러 복합적인 augmentation 방법 적용한 뒤에도 동일한 예측을 하도록 KLD 형태의 ConsistencyLoss를 regularizer로 사용하는 방법</li>
<li>장점/효과: Robustness 관점에서 좋은 성능 (Noise에 강건함)</li>
</ul>
<h3 id="autoaugment-cvpr-2019">AutoAugment (CVPR 2019)</h3>
<ul>
<li><a href="https://arxiv.org/pdf/1805.09501.pdf"target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1805.09501.pdf</a>
</li>
<li>한 줄 요약: 최적의 augmentation policy를 찾도록 RL 기반 학습</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li>Shorten, Connor, and Taghi M. Khoshgoftaar. &ldquo;A survey on image data augmentation for deep learning.&rdquo; Journal of big data 6.1 (2019): 1-48</li>
</ul></article>
<section class="article discussion">
    <script src="https://utteranc.es/client.js" repo="cse-study/cse-study.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
    </script>
</section></div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/ai/2022-05/220520-jax/"><span class="iconfont icon-article"></span>JAX Ecosystem</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">©2019 Notepadium.</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank" rel="noopener noreferrer">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank" rel="noopener noreferrer">Notepadium</a></p></div>
</section><script defer type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-e/4/LvThKH1gwzXhdbY2AsjR3rm7LHWyhIG5C0jiRfn8AN2eTN5ILeztWw0H9jmN" crossorigin="anonymous"></script>
        <script
            type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script><script src="/js/hljs.min.72e76ccf211868d08e31d7ca45c02501991bd760f28809c52045fa79fb7b7428664bb54ae875b46031ebc760c77b9562.js" integrity="sha384-cudszyEYaNCOMdfKRcAlAZkb12DyiAnFIEX6eft7dChmS7VK6HW0YDHrx2DHe5Vi"></script><script>hljs.initHighlightingOnLoad();</script></body>

</html>